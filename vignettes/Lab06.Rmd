---
title: "Lab06"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Lab06}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(Lab06)
```
This vignette contains the report for lab 6: writing fast R code. In this lab, different algorithms with different complexity have been implemented for the Knapsack problem to study the effects of the different algorithms with a focus on speed.


First generate knapsack objects with n=2000 and n=1000000 items respectively:
```{r}
RNGversion(min(as.character(getRversion()),"3.5.3"))

set.seed(42, kind = "Mersenne-Twister", normal.kind = "Inversion")

n <- 2000
knapsack_objects <-
  data.frame(
    w=sample(1:4000, size = n, replace = TRUE),
    v=runif(n = n, 0, 10000)
  )

n <- 1000000
knapsack_objects_greedy <-
  data.frame(
    w=sample(1:4000, size = n, replace = TRUE),
    v=runif(n = n, 0, 10000)
  )

```
We run the system.time() function 10 times with a for loop to obtain the average time of the function to reduce the time error and have a more precise comparison.

## 1.1.2 Brute force search

Time for n=16 objects:

```{r}
#- Set number of iterations and knapsack items
n_iter <- 10
n_select <- 16

system.time(for (i in 1:n_iter) brute_force_knapsack(x = knapsack_objects[1:n_select,], W = 3500))/n_iter

system.time(for (i in 1:n_iter) brute_force_knapsack(x = knapsack_objects[1:n_select,], W = 2000))/n_iter

```

It takes around 0.5s for both weights.

## 1.1.3 Dynamic programming

Time for n=500 objects:

```{r}
#- Set number of iterations and knapsack items
n_iter <- 10
n_select <- 500

system.time(for (i in 1:n_iter) knapsack_dynamic(x = knapsack_objects[1:n_select,],
                                                 W = 3500))/n_iter

system.time(for (i in 1:n_iter) knapsack_dynamic(x = knapsack_objects[1:n_select,], 
                                                 W = 2000))/n_iter
```
It takes around 0.7s for W=3500 and 0.3s for W=2000. It seems reasonable that the 
smaller weight takes shorter time since the table the algorithm has to 
construct becomes smaller with a smaller value for W.

## 1.1.4 Greedy heuristic

```{r}
n<-10
system.time(for (i in 1:n) greedy_knapsack(knapsack_objects[1:1200,],W=3500)) / n
#1000000 Objects

system.time(for (i in 1:n)greedy_knapsack(knapsack_objects_greedy[1:1000000,],W=3500))/n

```
How much time does it takes to run the algorithm for n = 1000000 objects?
It takes 5.4 seconds.
Approximately 4.9 seconds more than with 1200 objects.

## 1.1.5 Improvement of greedy heuristic

```{r}
n<-1
system.time(for (i in 1:n) greedy_knapsack(knapsack_objects[1:1200,],W=3500)) / n
greedy_knapsack(knapsack_objects[1:1200,],W=3500)
system.time(for (i in 1:n) greedy_knapsack(knapsack_objects[1:1200,],W=3500,"plus")) / n
greedy_knapsack(knapsack_objects[1:1200,],W=3500,"plus")
```
It is possible to return a better solution on the greedy algorithm. If the algorithm keeps finding the next value or values that fits in the snapback, instead of stoping one item before passing the limit. It will still be a gredy one, because it keeps loking for the next item(s) on the same order going in a decreasing order; and it has a O(n), because the time it takes to compute still increases as the number of items increase. Because the principle of finding and ordering the values has not change.

## 1.1.6 Profile your code and optimize your code

We compared three different main approaches to do the independent steps of the 
brute force algorithm, and within one of the main approaches also some sub types. 
The approaches were:

- for loop
- matrix calculations
- apply
    - 1a: part of the steps used variants of apply, and parts used matrix algebra
    - 1b: all steps used variants of apply, in separate calls
    - 2: all steps were collected into one function, that was used in apply (sapply)

The comparisons were made using W=3500.    
```{r}
#- Set number of iterations and knapsack items
n_iter <- 10
n_select <- 16

#- For loop
brute_force_knapsack(x = knapsack_objects[1:n_select,], W = 3500, type="forloop")
system.time(for (i in 1:n_iter) brute_force_knapsack(
  x = knapsack_objects[1:n_select,], W = 3500, type="forloop")) /n_iter

#- Matrix --------------------#
brute_force_knapsack(x = knapsack_objects[1:n_select,], W = 3500, type="matrix")
system.time(for (i in 1:n_iter) brute_force_knapsack(
  x = knapsack_objects[1:n_select,], W = 3500, type="matrix"))/n_iter

#- Apply --------------------#
brute_force_knapsack(x = knapsack_objects[1:n_select,], W = 3500, type="apply1a")
system.time(for (i in 1:n_iter) brute_force_knapsack(
  x = knapsack_objects[1:n_select,], W = 3500, type="apply1a"))/n_iter

brute_force_knapsack(x = knapsack_objects[1:n_select,], W = 3500, type="apply1b")
system.time(for (i in 1:n_iter) brute_force_knapsack(
  x = knapsack_objects[1:n_select,], W = 3500, type="apply1b"))/n_iter

brute_force_knapsack(x = knapsack_objects[1:n_select,], W = 3500, type="apply2")
system.time(for (i in 1:n_iter) brute_force_knapsack(
  x = knapsack_objects[1:n_select,], W = 3500, type="apply2"))/n_iter

```
The matrix approach reduced the time compared to the for loop, and the combined 
apply/matrix variant (apply1a) further reduced the time, The two other apply 
approaches (apply1b and apply2) however did not improve the time compared to the 
for loop.

Another way to improve the running time is to remove the items that have weight
greater than W from the beginning:

```{r}
#- Set number of iterations and knapsack items
n_iter <- 10
n_select <- 16

#- For loop
brute_force_knapsack(x = knapsack_objects[1:n_select,], W = 3500, type="forloop", 
                     filter_items=TRUE)
system.time(for (i in 1:n_iter) brute_force_knapsack(
  x = knapsack_objects[1:n_select,], W = 3500, type="forloop", filter_items=TRUE)) /n_iter
```
For the data in this example, it reduced the running time quite significantly 
compared to not excluding from the beginning the items with weight greater than W.


## 1.1.8 Parallelise brute force search

Three different parallelisation strategies were implemented using the parallel
package, analogous to the three apply approaches above:

- parallel package
    - 1a: part of the steps used variants of parApply, and parts used matrix algebra
    - 1b: all steps used variants of parApply, in separate calls
    - 2: all steps were collected into one function, that was used in parApply (parSapply)

The running times for the different approaches are studied below. Note that 
it was not possible to set the cores to the number of detected cores, since CRAN/
R CMD check only allows 2 cores. The results for n=2 cores are also compared to 
only using n=1 core.

```{r}
#- Set number of iterations and knapsack items
n_iter <- 10
n_select <- 16

#- Set number of cores
ncores <- 2

#- Note. number of available cores can be checked with:
ncores_available <- parallel::detectCores()

#- Run algorithms
brute_force_knapsack(x = knapsack_objects[1:n_select,], W = 3500, type="parallel1a",
                     ncores=ncores)
system.time(for (i in 1:n_iter) brute_force_knapsack(x = knapsack_objects[1:n_select,],
                                                     W = 3500, type="parallel1a", 
                                                     ncores=ncores))/n_iter

brute_force_knapsack(x = knapsack_objects[1:n_select,], W = 3500, type="parallel1b", 
                     ncores=ncores)
system.time(for (i in 1:n_iter) brute_force_knapsack(x = knapsack_objects[1:n_select,], 
                                                     W = 3500, type="parallel1b", 
                                                     ncores=ncores))/n_iter

brute_force_knapsack(x = knapsack_objects[1:n_select,], W = 3500, type="parallel2", 
                     ncores=ncores)
system.time(for (i in 1:n_iter) brute_force_knapsack(x = knapsack_objects[1:n_select,], 
                                                     W = 3500, type="parallel2", 
                                                     ncores=ncores))/n_iter
```
Parallel computations did not improve the running time in these implementations.

Try with only one (1) core:
```{r}
#- Set number of iterations and knapsack items
n_iter <- 10
n_select <- 16

#- Set number of cores
ncores <- 1

#- Run algorithms
brute_force_knapsack(x = knapsack_objects[1:n_select,], W = 3500, type="parallel1a", 
                     ncores=ncores)
system.time(for (i in 1:n_iter) brute_force_knapsack(x = knapsack_objects[1:n_select,], 
                                                     W = 3500, type="parallel1a", 
                                                     ncores=ncores))/n_iter

brute_force_knapsack(x = knapsack_objects[1:n_select,], W = 3500, type="parallel1b", 
                     ncores=ncores)
system.time( for (i in 1:n_iter) brute_force_knapsack(x = knapsack_objects[1:n_select,], 
                                                      W = 3500, type="parallel1b", 
                                                      ncores=ncores)) /n_iter

brute_force_knapsack(x = knapsack_objects[1:n_select,], W = 3500, type="parallel2", 
                     ncores=ncores)
system.time( for (i in 1:n_iter) brute_force_knapsack(x = knapsack_objects[1:n_select,], 
                                                      W = 3500, type="parallel2", 
                                                      ncores=ncores)) /n_iter

```
The running times for n=1 core do not seem to differ that much from using n=2 
cores in this implementation.
